{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f034c715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a822de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"30-60.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af9e505",
   "metadata": {},
   "outputs": [],
   "source": [
    "FAU_NAMES = data.columns[3:7]\n",
    "CONF_NAMES = data.columns[10:14]\n",
    "\n",
    "# have user input viable indices where bounding boxes are accurate\n",
    "viables = [11, 24, 25]\n",
    "faus = data.loc[viables, FAU_NAMES]\n",
    "fau_arr = np.asarray(faus)\n",
    "confs = data.loc[viables, CONF_NAMES]\n",
    "conf_arr = np.asarray(confs)\n",
    "\n",
    "clean_data = faus.join(confs)\n",
    "clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cc3af7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fau_arr\n",
    "conf_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41385638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_fau_scores(data):\n",
    "    \"\"\"\n",
    "        Get data per FAU without filtering for manually confirmed bounding box accuracy.\n",
    "        Run the same analytics as with clean data on all timestamps of the data matrix without checking\n",
    "        whether the bounding boxes were correctly identified at those points.\n",
    "    \"\"\"\n",
    "    \n",
    "    THRESHOLD = 0.90\n",
    "    \n",
    "    faus = {}\n",
    "    fs_sorted = {}\n",
    "    times = {}\n",
    "    \n",
    "    for i in range(len(FAU_NAMES)):\n",
    "        fau = FAU_NAMES[i]\n",
    "        conf = CONF_NAMES[i]\n",
    "        \n",
    "        mgs = data[fau].where(data[conf] >= THRESHOLD).dropna()\n",
    "        mgs_sorted = data.sort_values(conf, ascending=False)[fau]\n",
    "        sorted_arrs = np.asarray(mgs_sorted)\n",
    "        print(mgs)\n",
    "        #print(mgs_sorted, \"\\n\")\n",
    "        faus[fau] = np.asarray(mgs)\n",
    "        print(\"index\", mgs.index, \"\\n\")\n",
    "        times[fau] = mgs.index\n",
    "        fs_sorted[fau] = sorted_arrs\n",
    "    \n",
    "    return faus, times, fs_sorted\n",
    "\n",
    "def get_clean_fau_analytics():\n",
    "    \"\"\"\n",
    "        Get clean data per FAU after filtering for high confidence scores only.\n",
    "        \n",
    "        For each Facial Action Unit, filter for datapoints that correspond to high confidence values.\n",
    "        \n",
    "        Returns 3 dictionaries with:\n",
    "            - Faus: data arrays with all high confidence scores organized by FAU identity\n",
    "            - Times: label arrays containing timestamp identity for each included confidence score per FAU\n",
    "            - Scores sorted: dataframes containing all FAU scores sorted by confidence across each individual column\n",
    "    \"\"\"\n",
    "    THRESHOLD = 0.90\n",
    "    \n",
    "    faus = {}\n",
    "    fs_sorted = {}\n",
    "    times = {}\n",
    "    \n",
    "    for i in range(len(FAU_NAMES)):\n",
    "        fau = FAU_NAMES[i]\n",
    "        conf = CONF_NAMES[i]\n",
    "        \n",
    "        mgs = clean_data[fau].where(clean_data[conf] >= THRESHOLD).dropna()\n",
    "        mgs_sorted = clean_data.sort_values(conf, ascending=False)[fau]\n",
    "        sorted_arrs = np.asarray(mgs_sorted)\n",
    "        faus[fau] = np.asarray(mgs)\n",
    "        times[fau] = mgs.index\n",
    "        fs_sorted[fau] = sorted_arrs\n",
    "    \n",
    "    return faus, times, fs_sorted\n",
    "\n",
    "def display_analytics_report(faus, times, fs_sorted):\n",
    "    # user friendly report:\n",
    "    \n",
    "    tstamps = {}\n",
    "    [tstamps.update({k:np.asarray(data.loc[times[k], \"Timestamp(x)\"])}) for k in times.keys()]\n",
    "    \n",
    "    print(\"*** COMPLETED FAU ANALYTICS ON CLEAN DATAFRAME ***\\n\\n\")\n",
    "    \n",
    "    for fau in faus.keys():\n",
    "        print(\"\\n\\n**\", fau, \"**\\n\\n\")\n",
    "        print(\"For\", fau, \"Facial Action Unit:\\n\")\n",
    "        print(\"High confidence Mouse Grimace Scale scores for this clip:\\n\", faus[fau])\n",
    "        print(\"\\nCorresponding timestamps for high confidence MGS score:\\n\", tstamps[fau])\n",
    "        print(\"\\nAll viable Mouse Grimace Scale scores descending order of Confidence Score:\\n\", fs_sorted[fau])\n",
    "    \n",
    "\n",
    "def get_fau_scores(viables, fau, conf):\n",
    "    \"\"\"\n",
    "        Get arrays of Facial Action Unit scores across each row of data that has been determined to be viable through visual inspection.\n",
    "        IGNORE. not pursuing this anymore.\n",
    "    \"\"\"\n",
    "    THRESHOLD = 0.90\n",
    "    \n",
    "    fau_mgs = {}\n",
    "    for fau in FAU_NAMES:\n",
    "        fau_mgs[str(fau)] = []\n",
    "    \n",
    "    for v in range(len(viables)):\n",
    "        for fi in range(len(fau)):\n",
    "            if conf[v][fi] >= THRESHOLD:\n",
    "                pass\n",
    "                #print(fau_mgs[list(fau_mgs.keys())[fi]], fau[v][fi])\n",
    "                #fau_mgs[list(fau_mgs.keys())[fi]].append(fau[v][fi])\n",
    "    \n",
    "    print(fau_mgs)\n",
    "    return NotImplemented\n",
    "\n",
    "\n",
    "\n",
    "f,t,s = get_clean_fau_analytics()\n",
    "display_analytics_report(f,t,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9984e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_rows(temp):\n",
    "    \"\"\"\n",
    "        Get clean data per row after filtering for high confidence rows only.\n",
    "        \n",
    "        Filter for rows that correspond to high average confidence value across Facial Action Units.\n",
    "        Returns a dictionary with viable FAU scores at timepoints of accurate bounding box classification and high confidence scores across facial action units.\n",
    "    \"\"\"\n",
    "    THRESHOLD = 0.90\n",
    "    \n",
    "    # insert new column with average confidence value\n",
    "    if \"Avg Confidence\" in temp.columns.values:\n",
    "        temp = temp.drop(columns=['Avg Confidence'])\n",
    "    temp.insert(len(temp.columns), \"Avg Confidence\", np.mean(np.asarray(temp.loc[:, CONF_NAMES]), axis=1))\n",
    "    filtered = temp.sort_values(by='Avg Confidence', ascending=False)\n",
    "    fau = filtered.loc[:, FAU_NAMES]\n",
    "    conf = filtered.loc[:, CONF_NAMES]\n",
    "    avg = filtered.loc[:, 'Avg Confidence']\n",
    "    filtered = fau.join(avg)\n",
    "    # join confidence columns as well\n",
    "    #filtered = fau.join(avg).join(conf)\n",
    "    \n",
    "    return filtered\n",
    "    \n",
    "get_clean_rows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c8bda7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d00bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a751717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468ccd31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
